{"paragraphs":[{"text":"%md\n> Exploring data, traning a model and making predictions\n\n## Welcome to InsightEdge Getting started.\n\n##### We will use flight delay data to make predictions on which flights are likely to get delayed.\n##### We do the following steps:\n* Fetching data and loading it into the platform\n* Exproring the data via Spark and SQL queries\n* Enriching the data and processing it to get the relevant feature vector\n* Build and train it an ML model for prediction of flight delays\n* Test the model with real data\n\n##### You can run the code yourself. _(click `Run` button in each paragraph from top to bottom)_\n\n#### Fitting the data to ML model:\nWe are looking to get a binary prediction on weather our flight will be delayed or not.\nThere are many ML models that can be evaluted to try and find the model that is best suited for this task. In our case we will focus on a single model that typicall peforms well on such problems - `Random (Decision) Forest`. \nFlight delays are measured in minutes, positive number is the delay in minutes while negative number indicate a flight that was early.\nWe will use data such as the month, day and departure time as well as origin and destination airports as features we will feed into an ML model, in our case, Random Forest, to train it for best accuracy. \nWe will also supplement the feature vector with weather related data such as rain, wind and temperature. \n\n##### We will use:\n*2017 data for training our model\n*2018 data for evaluating our model accuracy\n*Then we will stream 2019 data and predict if the flight will get delayed.","user":"anonymous","dateUpdated":"2019-09-08T05:11:34-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<blockquote>\n  <p>Exploring data, traning a model and making predictions</p>\n</blockquote>\n<h2>Welcome to InsightEdge Getting started.</h2>\n<h5>We will use flight delay data to make predictions on which flights are likely to get delayed.</h5>\n<h5>We do the following steps:</h5>\n<ul>\n  <li>Fetching data and loading it into the platform</li>\n  <li>Exproring the data via Spark and SQL queries</li>\n  <li>Enriching the data and processing it to get the relevant feature vector</li>\n  <li>Build and train it an ML model for prediction of flight delays</li>\n  <li>Test the model with real data</li>\n</ul>\n<h5>You can run the code yourself. <em>(click <code>Run</code> button in each paragraph from top to bottom)</em></h5>\n<h4>Fitting the data to ML model:</h4>\n<p>We are looking to get a binary prediction on weather our flight will be delayed or not.<br/>There are many ML models that can be evaluted to try and find the model that is best suited for this task. In our case we will focus on a single model that typicall peforms well on such problems - <code>Random (Decision) Forest</code>.<br/>Flight delays are measured in minutes, positive number is the delay in minutes while negative number indicate a flight that was early.<br/>We will use data such as the month, day and departure time as well as origin and destination airports as features we will feed into an ML model, in our case, Random Forest, to train it for best accuracy.<br/>We will also supplement the feature vector with weather related data such as rain, wind and temperature. </p>\n<h5>We will use:</h5>\n<p>*2017 data for training our model<br/>*2018 data for evaluating our model accuracy<br/>*Then we will stream 2019 data and predict if the flight will get delayed.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1566455119308_666642321","id":"20190821-232519_1860033659","dateCreated":"2019-08-21T23:25:19-0700","dateStarted":"2019-09-08T05:11:34-0700","dateFinished":"2019-09-08T05:11:37-0700","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:31969"},{"text":"%md\n##### First Phase:\nFetch the relevant data.\nIn our case, we have the data in CSV file format. (In case the data is not available, it can be downloaded from: <https://insightedge-gettingstarted.s3.amazonaws.com/flightdelays20172018.csv.zip>)\nOnce loaded, explore the data with some SQL statements to understand the schema and how it behaves.","user":"anonymous","dateUpdated":"2019-09-08T05:11:37-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>First Phase:</h5>\n<p>Fetch the relevant data.<br/>In our case, we have the data in CSV file format. (In case the data is not available, it can be downloaded from: <a href=\"https://insightedge-gettingstarted.s3.amazonaws.com/flightdelays20172018.csv.zip\">https://insightedge-gettingstarted.s3.amazonaws.com/flightdelays20172018.csv.zip</a>)<br/>Once loaded, explore the data with some SQL statements to understand the schema and how it behaves.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1566810776406_139869750","id":"20190826-021256_100418820","dateCreated":"2019-08-26T02:12:56-0700","dateStarted":"2019-09-08T05:11:37-0700","dateFinished":"2019-09-08T05:11:37-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31970"},{"text":"%define\npackage model.v1\n\nimport com.gigaspaces.metadata._\nimport com.gigaspaces.metadata.index.SpaceIndexType;\nimport java.lang\nimport scala.beans.{BeanProperty}\nimport org.insightedge.scala.annotation._\nimport org.insightedge.spark.implicits.all._\n\n\n//Describe the data as Scala Case Class\n\ncase class FlightDelaysWithWeather(\n  @BeanProperty \n  @SpaceId\n  var id: String,\n  @BeanProperty \n  @SpaceIndex\n  var carrier: String,\n  @BeanProperty \n  @SpaceIndex\n  var flightNumber: String,\n  @SpaceIndex\n  @BeanProperty \n  var year: Integer,\n  @BeanProperty \n  var month: String,\n  @BeanProperty \n  var dayofMonth: String,\n  @BeanProperty \n  var dayOfWeek: String,\n  @BeanProperty \n  var crsDepTime: String,\n  @SpaceIndex\n  @BeanProperty \n  var depDelay15: java.lang.Double,\n  @BeanProperty \n  var depDelay: java.lang.Double,\n  @SpaceIndex\n  @BeanProperty \n  var origin: String,\n  @BeanProperty \n  var dest: String,\n  @BeanProperty \n  var awnd: String,\n  @BeanProperty \n  var prcp: String,\n  @BeanProperty \n  var snow: String,\n  @BeanProperty \n  var tmax: String,\n  @BeanProperty \n  var tmin: String,\n  @BeanProperty \n  var cancelled: String,\n    @BeanProperty \n  var date: Integer) {\n  def this() = this(null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null)\n}\n\n","user":"anonymous","dateUpdated":"2019-09-08T05:11:38-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res0: org.apache.zeppelin.dep.Dependency = org.apache.zeppelin.dep.Dependency@689e5dd6\n"}]},"apps":[],"jobName":"paragraph_1567323915545_-1753903989","id":"20190901-004515_1420239656","dateCreated":"2019-09-01T00:45:15-0700","dateStarted":"2019-09-08T05:11:38-0700","dateFinished":"2019-09-08T05:11:47-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31971"},{"title":"Load Flight Delay data","text":"%spark\n//explore data before we continue\n//WN - SouthWest, OO - SkyWest Airlines Inc., \"EV\" - ExpressJet Airlines LLC, \"B6\" - JetBlue, \"AS\" Alaska Airlines Inc. \"NK\" - Spirit Air Lines\", \"F9\" - \"Frontier Airlines Inc.\"\nval airlines = List (\"UA\",\"OO\",\"B6\",\"NK\", \"F9\")\n// ORD - Chicago, DFW - Dallas, DEN - Denver, SFO - San Francisco\nval airports = List (\"ORD\",\"DFW\",\"DEN\",\"SFO\")\nval flightDelaysDataFrame = sqlContext.read.option(\"header\", \"true\").option(\"inferschema\", \"true\").csv(\"/mnt/Downloads/flightdelays/flightdelays20172018.csv\").filter($\"Reporting_Airline\".isin(airlines:_*)).filter($\"Origin\".isin(airports:_*)).filter($\"cancelled\" === 0.0).filter($\"DayofMonth\" < 20.0)\nflightDelaysDataFrame.printSchema()\n// Create a temp view that we can query by SQL\nflightDelaysDataFrame.createOrReplaceTempView(\"FlightDelays\")\n","user":"anonymous","dateUpdated":"2019-09-08T05:11:47-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- Year: integer (nullable = true)\n |-- Month: integer (nullable = true)\n |-- DayofMonth: integer (nullable = true)\n |-- DayOfWeek: integer (nullable = true)\n |-- Reporting_Airline: string (nullable = true)\n |-- Tail_Number: string (nullable = true)\n |-- Flight_Number: integer (nullable = true)\n |-- Origin: string (nullable = true)\n |-- Dest: string (nullable = true)\n |-- CRSDepTime: integer (nullable = true)\n |-- DepDelay: double (nullable = true)\n |-- DepDel15: double (nullable = true)\n |-- cancelled: double (nullable = true)\n\nairlines: List[String] = List(UA, OO, B6, NK, F9)\nairports: List[String] = List(ORD, DFW, DEN, SFO)\nflightDelaysDataFrame: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: int, Month: int ... 11 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://10.0.2.15:4040/jobs/job?id=0","http://10.0.2.15:4040/jobs/job?id=1"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1565602348574_-2054269099","id":"20190812-123228_1439056817","dateCreated":"2019-08-12T12:32:28-0700","dateStarted":"2019-09-08T05:11:47-0700","dateFinished":"2019-09-08T05:12:14-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31972"},{"title":"Take a glance at the data","text":"%sql\nselect * from FlightDelays order by DepDelay Desc limit 5\n","user":"anonymous","dateUpdated":"2019-09-08T05:12:14-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{"columns":[{"name":"Year","visible":true,"width":150,"sort":{},"filters":[{}],"pinned":""},{"name":"Month","visible":true,"width":150,"sort":{},"filters":[{}],"pinned":""},{"name":"DayofMonth","visible":true,"width":150,"sort":{},"filters":[{}],"pinned":""},{"name":"DayOfWeek","visible":true,"width":"*","sort":{},"filters":[{}],"pinned":""},{"name":"Reporting_Airline","visible":true,"width":"*","sort":{},"filters":[{}],"pinned":""},{"name":"Tail_Number","visible":true,"width":"*","sort":{},"filters":[{}],"pinned":""},{"name":"Origin","visible":true,"width":"*","sort":{},"filters":[{}],"pinned":""},{"name":"Dest","visible":true,"width":"*","sort":{},"filters":[{}],"pinned":""},{"name":"CRSDepTime","visible":true,"width":"*","sort":{},"filters":[{}],"pinned":""},{"name":"DepDelay","visible":true,"width":"*","sort":{},"filters":[{}],"pinned":""},{"name":"DepDel15","visible":true,"width":"*","sort":{},"filters":[{}],"pinned":""},{"name":"cancelled","visible":true,"width":"*","sort":{"priority":0,"direction":"desc"},"filters":[{}],"pinned":""}],"scrollFocus":{},"selection":[],"grouping":{"grouping":[],"aggregations":[],"rowExpandedStates":{}},"treeView":{},"pagination":{"paginationCurrentPage":1,"paginationPageSize":250}},"tableColumnTypeState":{"names":{"Year":"string","Month":"string","DayofMonth":"string","DayOfWeek":"string","Reporting_Airline":"string","Tail_Number":"string","Flight_Number":"string","Origin":"string","Dest":"string","CRSDepTime":"string","DepDelay":"string","DepDel15":"string","cancelled":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"Year\tMonth\tDayofMonth\tDayOfWeek\tReporting_Airline\tTail_Number\tFlight_Number\tOrigin\tDest\tCRSDepTime\tDepDelay\tDepDel15\tcancelled\n2017\t3\t8\t3\tUA\tN213UA\t328\tDEN\tHNL\t1200\t1495.0\t1.0\t0.0\n2017\t6\t13\t2\tOO\tN898SK\t4478\tORD\tSLC\t754\t1437.0\t1.0\t0.0\n2018\t1\t3\t3\tOO\tN464SW\t3128\tDFW\tPIB\t1230\t1416.0\t1.0\t0.0\n2018\t3\t2\t5\tOO\tN145SY\t5483\tDFW\tSFO\t1931\t1396.0\t1.0\t0.0\n2018\t2\t9\t5\tOO\tN712SK\t2999\tDFW\tASE\t1640\t1377.0\t1.0\t0.0\n"},{"type":"TEXT","data":""}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://10.0.2.15:4040/jobs/job?id=2"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1566133567449_2044279672","id":"20190818-160607_881523454","dateCreated":"2019-08-18T16:06:07-0700","dateStarted":"2019-09-08T05:12:14-0700","dateFinished":"2019-09-08T05:12:31-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31973"},{"title":"Total number of Flight vs. number of Delayed flights by Origin Airport","text":"%sql\n\nselect Origin, count(*) as TotalFlights, SUM(DepDel15) as DelayedFlightsCount from FlightDelays group by Origin order by  DelayedFlightsCount/TotalFlights desc limit 15\n","user":"anonymous","dateUpdated":"2019-09-09T22:13:44-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"Origin":"string","TotalFlights":"string","DelayedFlights":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"stackedAreaChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"lineChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"Origin","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"TotalFlights","index":1,"aggr":"sum"},{"name":"DelayedFlightsCount","index":2,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","editorHide":false,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"Origin\tTotalFlights\tDelayedFlightsCount\nSFO\t127175\t27298.0\nORD\t203768\t43373.0\nDFW\t27611\t5154.0\nDEN\t166684\t28475.0\n"},{"type":"TEXT","data":""}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://10.0.2.15:4040/jobs/job?id=3"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1565769096081_780201073","id":"20190814-105136_1961434103","dateCreated":"2019-08-14T10:51:36-0700","dateStarted":"2019-09-08T05:12:31-0700","dateFinished":"2019-09-08T05:12:46-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31974"},{"title":"Airport popularity","text":"%sql\nselect origin, count(*) as vol from  FlightDelays group by origin order by vol desc","user":"anonymous","dateUpdated":"2019-09-08T05:12:46-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"pieChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"origin":"string","vol":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"origin\tvol\nORD\t203768\nDEN\t166684\nSFO\t127175\nDFW\t27611\n"},{"type":"TEXT","data":""}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://10.0.2.15:4040/jobs/job?id=4"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1565777362002_-1906796673","id":"20190814-130922_1525095978","dateCreated":"2019-08-14T13:09:22-0700","dateStarted":"2019-09-08T05:12:46-0700","dateFinished":"2019-09-08T05:12:58-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31975"},{"text":"%md\n\n#### Second Phase:\n* Configure an InsightEdge context\n* Provide InsightEdge with type information on the data we loaded\n* Load the data to the InsightEdge inmemory store (This will speed up data access)\n","user":"anonymous","dateUpdated":"2019-09-08T05:12:58-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Second Phase:</h4>\n<ul>\n  <li>Configure an InsightEdge context</li>\n  <li>Provide InsightEdge with type information on the data we loaded</li>\n  <li>Load the data to the InsightEdge inmemory store (This will speed up data access)</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1566811410938_2065532546","id":"20190826-022330_1347205260","dateCreated":"2019-08-26T02:23:30-0700","dateStarted":"2019-09-08T05:12:58-0700","dateFinished":"2019-09-08T05:12:58-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31976"},{"title":"Initialize Spark with InsightEdge context ","text":"%spark\n\nimport org.insightedge.spark.implicits.all._\nimport org.insightedge.spark.context.InsightEdgeConfig\n\n//Change space name here if not working with default\nval ieConfig = new InsightEdgeConfig(\"demo\")\n\nsc.initializeInsightEdgeContext(ieConfig)\n","user":"anonymous","dateUpdated":"2019-09-08T05:12:58-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.insightedge.spark.implicits.all._\nimport org.insightedge.spark.context.InsightEdgeConfig\nieConfig: org.insightedge.spark.context.InsightEdgeConfig = InsightEdgeConfig(demo,None,None)\nres2: org.apache.spark.SparkContext = org.apache.spark.SparkContext@38a5e9f5\n"}]},"apps":[],"jobName":"paragraph_1565778749157_1241131483","id":"20190814-133229_440702495","dateCreated":"2019-08-14T13:32:29-0700","dateStarted":"2019-09-08T05:12:58-0700","dateFinished":"2019-09-08T05:12:59-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31977"},{"title":"Register type with the grid","text":"/*import com.gigaspaces.metadata._\nimport com.gigaspaces.metadata.index.SpaceIndexType;\nimport java.lang\n\n\nval typeDescriptor: SpaceTypeDescriptor = new SpaceTypeDescriptorBuilder(\"FlightDelay\").idProperty(\"id\", true)\n                .addFixedProperty(\"Origin\", \"java.lang.String\")\n                .addFixedProperty(\"Year\", \"java.lang.Integer\")\n                .addFixedProperty(\"DayofMonth\", \"java.lang.Integer\")\n                .addFixedProperty(\"DepDelay\", \"java.lang.Double\")\n                .addPropertyIndex(\"Origin\", SpaceIndexType.EQUAL)\n                .addPropertyIndex(\"Year\", SpaceIndexType.EQUAL)\n                .addFixedProperty(\"Tail_Number\", \"java.lang.String\")\n                .routingProperty(\"Tail_Number\")\n                .addPropertyIndex(\"DepDelay\", SpaceIndexType.ORDERED)\n                .create();\n        // Register type:\nsc.grid.getTypeManager().registerTypeDescriptor(typeDescriptor)\n\n\n\n*/","user":"anonymous","dateUpdated":"2019-09-08T05:12:59-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":88,"optionOpen":false}}},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1565769337521_1216815935","id":"20190814-105537_1546549879","dateCreated":"2019-08-14T10:55:37-0700","dateStarted":"2019-09-08T05:12:59-0700","dateFinished":"2019-09-08T05:12:59-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31978"},{"title":"Write the FlightDelay data to the in memory store","text":"%spark\nimport org.apache.spark.sql.SaveMode\nimport model.v1._\n\nprint(\"Writing to in-memory store \" + flightDelaysDataFrame.count + \"entries\")\n\nval flightDelaysRDD = flightDelaysDataFrame.map{rec => FlightDelaysWithWeather(\"\"+rec.getAs(\"Year\")+\":\"+rec.getAs(\"Month\")+\":\"+rec(2)+\":\"+rec.getAs(\"DayOfWeek\")+\":\"+rec.getAs(\"CRSDepTime\")+\":\"+rec.getAs(\"Flight_Number\"), \"\"+rec.getAs(\"Reporting_Airline\") , \"\"+rec.getAs(\"Flight_Number\") ,(\"\"+rec.getAs(\"Year\")).toInt,\"\"+rec.getAs(\"Month\"),\"\"+rec(2),\"\"+rec.getAs(\"DayOfWeek\"),\"\"+rec.getAs(\"CRSDepTime\"),(\"\"+rec.getAs(\"DepDel15\")).toDouble,(\"\"+rec.getAs(\"DepDelay\")).toDouble,\"\"+rec.getAs(\"Origin\"),\"\"+rec.getAs(\"Dest\"), null, null, null, null, null, null, null)}\n\nflightDelaysRDD.rdd.saveToGrid()","user":"anonymous","dateUpdated":"2019-09-08T05:12:59-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Writing to in-memory store 525238entries2019-09-08 05:13:11,679 CONFIG [com.gigaspaces.logger] - Log file: /home/vagrant/gigaspaces-insightedge-enterprise-14.5.0-patch-c-1/logs/2019-09-08~05.13-gigaspaces-service-127.0.1.1-29522.log\nimport org.apache.spark.sql.SaveMode\nimport model.v1._\nflightDelaysRDD: org.apache.spark.sql.Dataset[model.v1.FlightDelaysWithWeather] = [id: string, carrier: string ... 17 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://10.0.2.15:4040/jobs/job?id=5","http://10.0.2.15:4040/jobs/job?id=6"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1565781217833_-312298590","id":"20190814-141337_971258379","dateCreated":"2019-08-14T14:13:37-0700","dateStarted":"2019-09-08T05:12:59-0700","dateFinished":"2019-09-08T05:13:33-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31979"},{"title":"Query the data directly from the in memory grid","text":"%insightedge_jdbc\n\nselect * from FlightDelaysWithWeather limit 5\n","user":"anonymous","dateUpdated":"2019-09-08T05:13:33-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"awnd":"string","cancelled":"string","carrier":"string","crsDepTime":"string","date":"string","dayOfWeek":"string","dayofMonth":"string","depDelay":"string","depDelay15":"string","dest":"string","flightNumber":"string","id":"string","month":"string","origin":"string","prcp":"string","snow":"string","tmax":"string","tmin":"string","year":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"awnd\tcancelled\tcarrier\tcrsDepTime\tdate\tdayOfWeek\tdayofMonth\tdepDelay\tdepDelay15\tdest\tflightNumber\tid\tmonth\torigin\tprcp\tsnow\ttmax\ttmin\tyear\nnull\tnull\tNK\t2315\tnull\t4\t8\t10.0\t0.0\tLAS\t817\t2018:11:8:4:2315:817\t11\tDFW\tnull\tnull\tnull\tnull\t2018\nnull\tnull\tNK\t1746\tnull\t1\t12\t-6.0\t0.0\tLGA\t630\t2018:11:12:1:1746:630\t11\tORD\tnull\tnull\tnull\tnull\t2018\nnull\tnull\tNK\t1807\tnull\t1\t12\t6.0\t0.0\tFLL\t470\t2018:11:12:1:1807:470\t11\tDFW\tnull\tnull\tnull\tnull\t2018\nnull\tnull\tNK\t1641\tnull\t1\t5\t5.0\t0.0\tMSP\t382\t2018:11:5:1:1641:382\t11\tDEN\tnull\tnull\tnull\tnull\t2018\nnull\tnull\tNK\t1610\tnull\t1\t12\t15.0\t1.0\tRSW\t223\t2018:11:12:1:1610:223\t11\tORD\tnull\tnull\tnull\tnull\t2018\n"}]},"apps":[],"jobName":"paragraph_1565789829211_-1160925091","id":"20190814-163709_2074768724","dateCreated":"2019-08-14T16:37:09-0700","dateStarted":"2019-09-08T05:13:33-0700","dateFinished":"2019-09-08T05:13:40-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31980"},{"title":"Access the in-memory store with predicate push-down for better performance","text":"%spark\n\nval airports = List (\"ORD\",\"DFW\",\"DEN\",\"SFO\")\n\n\nval origin =  z.select(\"origin\", Seq((\"ORD\",\"O'hare International (chicago)\"),\n                                                  (\"DFW\",\"Dallas International\"),\n                                                  (\"DEN\", \"Denver\"), \n                                                  (\"SFO\", \"San Francissco\")))\nval filtered_df = spark.read.grid[FlightDelaysWithWeather].where(\"depDelay > 0 and origin = '\" + origin  + \"'\")\nfiltered_df.describe(\"depDelay\").show\n","user":"anonymous","dateUpdated":"2019-09-08T05:13:40-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","runOnSelectionChange":true,"title":true},"settings":{"params":{"carrier":"ORD","origin":"SFO","day":""},"forms":{"origin":{"type":"Select","options":[{"value":"ORD","displayName":"O'hare International (chicago)","$$hashKey":"object:32231"},{"value":"DFW","displayName":"Dallas International","$$hashKey":"object:32232"},{"value":"DEN","displayName":"Denver","$$hashKey":"object:32233"},{"value":"SFO","displayName":"San Francissco","$$hashKey":"object:32234"}],"name":"origin","displayName":"origin","defaultValue":"","hidden":false,"$$hashKey":"object:32226"}}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------+-----------------+\n|summary|         depDelay|\n+-------+-----------------+\n|  count|            45388|\n|   mean|43.67257865515114|\n| stddev| 62.6224494968507|\n|    min|              1.0|\n|    max|           1241.0|\n+-------+-----------------+\n\nairports: List[String] = List(ORD, DFW, DEN, SFO)\norigin: Object = SFO\nfiltered_df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, carrier: string ... 17 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://10.0.2.15:4040/jobs/job?id=7"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1566799046049_94268754","id":"20190825-225726_1724838668","dateCreated":"2019-08-25T22:57:26-0700","dateStarted":"2019-09-08T05:13:40-0700","dateFinished":"2019-09-08T05:13:42-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31981"},{"text":"%insightedge_jdbc\n\nselect flightNumber,  (1 -sum( depDelay15)/count(depDelay15)) as on_time_ratio, max(depDelay) as max_delay from FlightDelaysWithWeather group by flightNumber  having   count(depDelay15) > 100 order by on_time_ratio desc  limit 10\n","user":"anonymous","dateUpdated":"2019-09-08T05:13:42-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"flightNumber":"string","on_time_ratio":"string","max_delay":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"flightNumber","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"on_time_ratio","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"flightNumber\ton_time_ratio\tmax_delay\n2405\t0.9708994708994709\t215.0\n2107\t0.9705882352941176\t78.0\n44\t0.9606741573033708\t518.0\n2192\t0.9570552147239264\t111.0\n261\t0.9553264604810997\t138.0\n867\t0.9534368070953437\t167.0\n237\t0.9503205128205128\t207.0\n1896\t0.9487179487179487\t1086.0\n1192\t0.9464882943143813\t134.0\n1187\t0.946058091286307\t270.0\n"}]},"apps":[],"jobName":"paragraph_1567928661712_1350152362","id":"20190908-004421_1841609863","dateCreated":"2019-09-08T00:44:21-0700","dateStarted":"2019-09-08T05:13:42-0700","dateFinished":"2019-09-08T05:13:44-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31982"},{"text":"%md\n\n#### Third Phase:\n\nFetch daily weather (we have it stored in a CSV file. (Can be downloaded from <https://insightedge-gettingstarted.s3.amazonaws.com/weather2017_8.csv.zip>) and merge it with the flight delays data.\n##### DistributedTasks \nFor Merging the weather meterics with the flight delay data, we will use the DistributedTasks capability that let us define code that will execute in a distributed fashion over the in-memory data and can take advantage of the perfomance gains from locality/same process memroy space.\n\nThen, query the data just to see the fields that were added\n","user":"anonymous","dateUpdated":"2019-09-08T05:13:44-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Third Phase:</h4>\n<p>Fetch daily weather (we have it stored in a CSV file. (Can be downloaded from <a href=\"https://insightedge-gettingstarted.s3.amazonaws.com/weather2017_8.csv.zip\">https://insightedge-gettingstarted.s3.amazonaws.com/weather2017_8.csv.zip</a>) and merge it with the flight delays data.</p>\n<h5>DistributedTasks</h5>\n<p>For Merging the weather meterics with the flight delay data, we will use the DistributedTasks capability that let us define code that will execute in a distributed fashion over the in-memory data and can take advantage of the perfomance gains from locality/same process memroy space.</p>\n<p>Then, query the data just to see the fields that were added</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1566811797508_1026939002","id":"20190826-022957_1704419410","dateCreated":"2019-08-26T02:29:57-0700","dateStarted":"2019-09-08T05:13:44-0700","dateFinished":"2019-09-08T05:13:44-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31983"},{"title":"Enrich the Flights delay data with weather information","text":"%spark\nimport org.apache.spark.SparkContext._\n\nimport spark.implicits._\n\n\nval weatherDataFrame = sqlContext.read.option(\"header\", \"true\").option(\"inferschema\", \"true\").csv(\"/mnt/Downloads/flightdelays/weather2017_8.csv\")\n\n\n//Add task for merging the weather and flight delays","user":"anonymous","dateUpdated":"2019-09-08T05:13:44-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.SparkContext._\nimport spark.implicits._\nweatherDataFrame: org.apache.spark.sql.DataFrame = [Date: int, Station: string ... 5 more fields]\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://10.0.2.15:4040/jobs/job?id=8","http://10.0.2.15:4040/jobs/job?id=9"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1566133753108_1106777407","id":"20190818-160913_12361618","dateCreated":"2019-08-18T16:09:13-0700","dateStarted":"2019-09-08T05:13:44-0700","dateFinished":"2019-09-08T05:13:45-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31984"},{"title":"Register additional types with the grid","text":"import model.v1._\nimport com.gigaspaces.metadata._\nimport com.gigaspaces.metadata.index.SpaceIndexType;\nimport java.lang\nimport scala.beans.{BeanProperty}\nimport org.insightedge.scala.annotation._\nimport org.insightedge.spark.implicits.all._\n\n\nval typeDescriptor: SpaceTypeDescriptor = new SpaceTypeDescriptorBuilder(\"Weather\").idProperty(\"id\", true)\n                .addFixedProperty(\"Date\", \"java.lang.String\")\n                .addFixedProperty(\"Station\", \"java.lang.String\")\n                .addPropertyIndex(\"Date\", SpaceIndexType.EQUAL)\n                .addPropertyIndex(\"Station\", SpaceIndexType.EQUAL)\n                .routingProperty(\"Date\")\n                .create();\n                \n        // Register type:\nsc.grid.getTypeManager().registerTypeDescriptor(typeDescriptor)\nsc.grid.getTypeManager.registerTypeDescriptor(classOf[FlightDelaysWithWeather])\n","user":"anonymous","dateUpdated":"2019-09-08T05:13:45-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import model.v1._\nimport com.gigaspaces.metadata._\nimport com.gigaspaces.metadata.index.SpaceIndexType\nimport java.lang\nimport scala.beans.BeanProperty\nimport org.insightedge.scala.annotation._\nimport org.insightedge.spark.implicits.all._\ntypeDescriptor: com.gigaspaces.metadata.SpaceTypeDescriptor = TypeDesc[typeName=Weather, checksum=2012354847, codebase=null, superTypesNames=[Weather, java.lang.Object], supportsDynamicProperties=true, supportsOptimisticLocking=false, systemType=false, replicatable=true, blobstoreEnabled=true, storageType=OBJECT, fifoSupport=OFF, idPropertyName=id, idAutoGenerate=true, routingPropertyName=Date, fifoGroupingPropertyName=null, sequenceNumberPropertyName=null, objectClass=, documentWrapperClass=com.gigaspaces.document.SpaceDocument, fixedProperties=[Prope..."}]},"apps":[],"jobName":"paragraph_1566974893673_1317287651","id":"20190827-234813_998795403","dateCreated":"2019-08-27T23:48:13-0700","dateStarted":"2019-09-08T05:13:45-0700","dateFinished":"2019-09-08T05:13:46-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31985"},{"title":"Write Weather data to memory","text":"%spark\nweatherDataFrame.write.mode(SaveMode.Overwrite).grid(\"Weather\")","user":"anonymous","dateUpdated":"2019-09-08T05:13:46-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://10.0.2.15:4040/jobs/job?id=10"],"interpreterSettingId":"spark"}},"apps":[],"jobName":"paragraph_1566975037588_-17603255","id":"20190827-235037_392240904","dateCreated":"2019-08-27T23:50:37-0700","dateStarted":"2019-09-08T05:13:46-0700","dateFinished":"2019-09-08T05:13:47-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31986"},{"title":"Define a task that will enrich the Flights delay records with relevant weather metrics","text":"%spark\nimport  model.v1._\nimport com.gigaspaces.async.AsyncResult\nimport org.openspaces.core.executor.DistributedTask\nimport org.insightedge.scala.annotation._\nimport scala.collection.JavaConversions._\nimport org.slf4j.{Logger, LoggerFactory}\nimport org.openspaces.core.GigaSpace\nimport org.openspaces.core.executor.TaskGigaSpace\nimport scala.beans.{BeanProperty}\nimport com.gigaspaces.document.SpaceDocument\nimport scala.collection.mutable.ListBuffer\nimport com.j_spaces.core.client.SQLQuery\n\n\nclass MergeTask extends DistributedTask[java.lang.Integer, java.lang.Integer] {\n  private val logger = LoggerFactory.getLogger(classOf[MergeTask])\n  @TaskGigaSpace @transient private val gs: GigaSpace = null\n\noverride def execute(): Integer = {\n    if(gs != null) {\n      val clusteredProxy = gs.getClustered()\n      logger.info(\"execute returned from: \" + gs.getSpaceName)\n        val template =new SQLQuery[FlightDelaysWithWeather](classOf[FlightDelaysWithWeather], \"tmin is null\")\n        val weatherTemplate =new SpaceDocument(\"Weather\");\n        var writtenCount:Integer = 0\n        var retArray:Array[FlightDelaysWithWeather] = null\n        logger.info(\"Created template\")\n        try {\n            while ( {retArray = gs.takeMultiple(template, 1000);retArray  != null && retArray.length > 0}) {\n                var writeCollection = new ListBuffer[FlightDelaysWithWeather]\n                for (rec <- retArray) {\n                  val dateField:Int = (\"%d%02d%02d\".format(rec.year.toInt, rec.month.toInt, rec.dayofMonth.toInt)).toInt\n                  val origin:String =  rec.origin\n                  weatherTemplate.setProperty(\"Date\", dateField)\n                  weatherTemplate.setProperty(\"Station\", origin)\n                  val weather = clusteredProxy.read(weatherTemplate)\n                  if (weather != null) {\n                    rec.awnd = \"\" + weather.getProperty(\"AWND\")\n                    rec.prcp = \"\" + weather.getProperty(\"PRCP\")\n                    rec.snow = \"\" + weather.getProperty(\"SNOW\")\n                    rec.tmin = \"\" + weather.getProperty(\"TMIN\")\n                    rec.tmax = \"\" + weather.getProperty(\"TMAX\")\n                    rec.date =  dateField\n                    writeCollection += rec\n                  }\n                }\n                if(writeCollection.length > 0) {\n                    gs.writeMultiple(writeCollection.toArray)\n                } \n                writtenCount += writeCollection.length\n            }\n        } catch {\n            case e: Exception => logger.warn(e.getMessage, e)\n        }\n      logger.info(\"Finished task \" + writtenCount)\n\n      return writtenCount\n    } else {\n      logger.info(\"gs Proxy not available\")\n        return -1\n        \n    }\n  }\n  override def reduce(results: java.util.List[AsyncResult[Integer]]): java.lang.Integer = {\n    logger.info(\"In Reduce\")\n    return results.map(_.getResult().intValue()).sum\n  }}\n\n","user":"anonymous","dateUpdated":"2019-09-08T05:13:47-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import model.v1._\nimport com.gigaspaces.async.AsyncResult\nimport org.openspaces.core.executor.DistributedTask\nimport org.insightedge.scala.annotation._\nimport scala.collection.JavaConversions._\nimport org.slf4j.{Logger, LoggerFactory}\nimport org.openspaces.core.GigaSpace\nimport org.openspaces.core.executor.TaskGigaSpace\nimport scala.beans.BeanProperty\nimport com.gigaspaces.document.SpaceDocument\nimport scala.collection.mutable.ListBuffer\nimport com.j_spaces.core.client.SQLQuery\ndefined class MergeTask\n"}]},"apps":[],"jobName":"paragraph_1567316654995_-1231967246","id":"20190831-224414_1776282136","dateCreated":"2019-08-31T22:44:14-0700","dateStarted":"2019-09-08T05:13:47-0700","dateFinished":"2019-09-08T05:13:47-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31987"},{"title":"Execute the distributed task and get the enriched data as Spark dataframe","text":"%spark\nimport com.gigaspaces.async.AsyncFuture;\nimport org.insightedge.spark.implicits.all._\n\nval future:AsyncFuture[Integer] = sc.grid.execute(new MergeTask())\nval result = future.get()\n\n","user":"anonymous","dateUpdated":"2019-09-08T05:13:47-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import com.gigaspaces.async.AsyncFuture\nimport org.insightedge.spark.implicits.all._\nfuture: com.gigaspaces.async.AsyncFuture[Integer] = org.openspaces.core.transaction.internal.InternalAsyncFuture@53bf4cd5\nresult: Integer = 525155\n"}]},"apps":[],"jobName":"paragraph_1567316710578_905724253","id":"20190831-224510_2052488220","dateCreated":"2019-08-31T22:45:10-0700","dateStarted":"2019-09-08T05:13:47-0700","dateFinished":"2019-09-08T05:14:42-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31988"},{"title":"Take a Glance at the enriched data","text":"%insightedge_jdbc\n\nselect carrier , origin, dest, depDelay, awnd, prcp, snow, tmin, tmax   from FlightDelaysWithWeather where awnd is not null limit 20\n","user":"anonymous","dateUpdated":"2019-09-08T05:30:12-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"carrier":"string","origin":"string","dest":"string","depDelay":"string","awnd":"string","prcp":"string","snow":"string","tmin":"string","tmax":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","title":true,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"carrier\torigin\tdest\tdepDelay\tawnd\tprcp\tsnow\ttmin\ttmax\nUA\tDEN\tORD\t-4.0\t51\t0\t0\t67\t244\nUA\tORD\tLAX\t4.0\t35\t0\t0\t106\t217\nUA\tORD\tBWI\t133.0\t53\t0\t0\t100\t206\nUA\tORD\tSLC\t-4.0\t38\t0\t0\t183\t311\nOO\tDFW\tSLC\t0.0\t36\t803\t0\t61\t189\nUA\tSFO\tSNA\t14.0\t69\t0\t0\t156\t217\nUA\tORD\tPHX\t-6.0\t30\t117\t0\t-10\t56\nF9\tSFO\tCOS\t27.0\t69\t0\t0\t156\t217\nUA\tDEN\tBIL\t3.0\t64\t23\t0\t6\t39\nUA\tORD\tORF\t1.0\t27\t0\t0\t17\t133\nUA\tSFO\tLAS\t-6.0\t47\t0\t0\t94\t244\nUA\tSFO\tMSY\t42.0\t83\t0\t0\t100\t172\nOO\tORD\tSPI\t-8.0\t39\t0\t0\t83\t278\nOO\tORD\tSDF\t-10.0\t65\t0\t0\t161\t306\nOO\tSFO\tSLC\t-4.0\t47\t0\t0\t111\t206\nOO\tSFO\tPSC\t6.0\t34\t0\t0\t33\t94\nOO\tSFO\tPSP\t-11.0\t18\t0\t0\t50\t111\nUA\tORD\tPHX\t-2.0\t40\t0\t0\t-88\t-27\nOO\tORD\tOMA\t-5.0\t57\t0\t0\t167\t278\nOO\tORD\tSBN\t-7.0\t34\t0\t0\t144\t250\n"}]},"apps":[],"jobName":"paragraph_1566137974889_-70390595","id":"20190818-171934_1385212060","dateCreated":"2019-08-18T17:19:34-0700","dateStarted":"2019-09-08T05:30:12-0700","dateFinished":"2019-09-08T05:30:17-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31989"},{"text":"%md\n\n#### Forth Phase:\n\nUse the merged data to prepare features vectors for all the fields we want to fit in our model. Label each vector with the resulted delay\n","user":"anonymous","dateUpdated":"2019-09-08T02:52:34-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Forth Phase:</h4>\n<p>Use the merged data to prepare features vectors for all the fields we want to fit in our model. Label each vector with the resulted delay</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1566811978035_1767398597","id":"20190826-023258_963848778","dateCreated":"2019-08-26T02:32:58-0700","dateStarted":"2019-09-08T02:52:34-0700","dateFinished":"2019-09-08T02:52:34-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31990"},{"title":"Prepare the feature vector for the ML model","text":"%spark\nimport spark.implicits._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.feature.StandardScaler\nimport org.insightedge.scala.annotation._\nimport scala.beans.{BeanProperty}\n\n\ndef parseData(vals: Array[Double]): LabeledPoint = {\n   LabeledPoint(vals(0), Vectors.dense(vals.drop(1)))\n}\n\ndef prepareFeaturesLabeledPoint(_flightDelayswithWeatherDataSet: Dataset[FlightDelaysWithWeather]): RDD[LabeledPoint] = {\n    val featuresVectors = _flightDelayswithWeatherDataSet.map((o: FlightDelaysWithWeather) => Array(o.depDelay15.doubleValue(),  o.month.toDouble, o.dayOfWeek.toDouble,\n        (\"%04d\".format(o.crsDepTime.toInt).take(2)).toDouble, o.awnd.toDouble, o.prcp.toDouble, o.tmax.toDouble, o.tmin.toDouble))    \n     featuresVectors.rdd.map(parseData)\n} \n\n\n\nval traningData = prepareFeaturesLabeledPoint(FlightDelaysWithWeatherDataframe.filter(\"Year = 2017\"))\nval validationData = prepareFeaturesLabeledPoint(FlightDelaysWithWeatherDataframe.filter(\"Year = 2018\"))\n\n\n","user":"anonymous","dateUpdated":"2019-09-08T03:31:07-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import spark.implicits._\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.Dataset\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.feature.StandardScaler\nimport org.insightedge.scala.annotation._\nimport scala.beans.BeanProperty\nparseData: (vals: Array[Double])org.apache.spark.mllib.regression.LabeledPoint\nprepareFeaturesLabeledPoint: (_flightDelayswithWeatherDataSet: org.apache.spark.sql.Dataset[model.v1.FlightDelaysWithWeather])org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint]\ntraningData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[88] at map at <console>:114\nvalidationData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.reg..."}]},"apps":[],"jobName":"paragraph_1566211542004_435195428","id":"20190819-134542_2030099805","dateCreated":"2019-08-19T13:45:42-0700","dateStarted":"2019-09-08T03:31:07-0700","dateFinished":"2019-09-08T03:31:09-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31991"},{"text":"%md\n\n#### Fifth Phase\n\nWe will use the Random Forst model (forest of decision trees) with Classification strategy.\nThe 2017 data which we prepared before will be used to train the model.\nThe result is a fitted or trained model. \nWe will evaluted this model using the helper eval_metrics and Metrics class which will rate each prediction \n* TP - True Positive\n* TN - True Negative\n* FP - False Positive\n* FN - False Negative \n\nWhich we will then sum it to evalute accuracy.\nWe will use the 2018 data to run this evaluation and decide if the accuracy satisfy our requerments\n\n","user":"anonymous","dateUpdated":"2019-09-08T02:52:35-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Fifth Phase</h4>\n<p>We will use the Random Forst model (forest of decision trees) with Classification strategy.<br/>The 2017 data which we prepared before will be used to train the model.<br/>The result is a fitted or trained model.<br/>We will evaluted this model using the helper eval_metrics and Metrics class which will rate each prediction<br/>* TP - True Positive<br/>* TN - True Negative<br/>* FP - False Positive<br/>* FN - False Negative </p>\n<p>Which we will then sum it to evalute accuracy.<br/>We will use the 2018 data to run this evaluation and decide if the accuracy satisfy our requerments</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1566813337774_-1442141748","id":"20190826-025537_806156844","dateCreated":"2019-08-26T02:55:37-0700","dateStarted":"2019-09-08T02:52:35-0700","dateFinished":"2019-09-08T02:52:35-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31992"},{"title":"Train Model and save it to the grid","text":"%spark\n\nimport org.apache.spark.mllib.tree.RandomForest\nimport org.apache.spark.mllib.tree.configuration.Strategy\nimport org.insightedge.spark.implicits.all._\n\n\nval treeStrategy = Strategy.defaultStrategy(\"Classification\")\nval numTrees = 10 \nval featureSubsetStrategy = \"auto\" // Let the algorithm choose\nval predictFlightDelaysRFModel = RandomForest.trainClassifier(traningData, treeStrategy, numTrees, featureSubsetStrategy, seed = 123)\n//predictFlightDelaysRFModel.saveToGrid(sc, \"predictFlightDelaysRFModel\")","user":"anonymous","dateUpdated":"2019-09-08T03:31:17-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.mllib.tree.RandomForest\nimport org.apache.spark.mllib.tree.configuration.Strategy\nimport org.insightedge.spark.implicits.all._\ntreeStrategy: org.apache.spark.mllib.tree.configuration.Strategy = org.apache.spark.mllib.tree.configuration.Strategy@25493472\nnumTrees: Int = 10\nfeatureSubsetStrategy: String = auto\npredictFlightDelaysRFModel: org.apache.spark.mllib.tree.model.RandomForestModel =\nTreeEnsembleModel classifier with 10 trees\n"}]},"apps":[],"jobName":"paragraph_1566287669155_-1175975782","id":"20190820-105429_26620422","dateCreated":"2019-08-20T10:54:29-0700","dateStarted":"2019-09-08T03:31:17-0700","dateFinished":"2019-09-08T03:31:29-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31993"},{"title":"Define the performance metrics","text":"%spark\nimport org.apache.spark.rdd._\nimport org.apache.spark.rdd.RDD\n\n// Function to compute evaluation metrics\ndef eval_metrics(labelsAndPreds: RDD[(Double, Double)]) : Tuple2[Array[Double], Array[Double]] = {\n    val tp = labelsAndPreds.filter(r => r._1==1 && r._2==1).count.toDouble\n    val tn = labelsAndPreds.filter(r => r._1==0 && r._2==0).count.toDouble\n    val fp = labelsAndPreds.filter(r => r._1==1 && r._2==0).count.toDouble\n    val fn = labelsAndPreds.filter(r => r._1==0 && r._2==1).count.toDouble\n    \n    val precision = tp / (tp+fp)\n    val recall = tp / (tp+fn)\n    val F_measure = 2*precision*recall / (precision+recall)\n    val accuracy = (tp+tn) / (tp+tn+fp+fn)\n    new Tuple2(Array(tp, tn, fp, fn), Array(precision, recall, F_measure, accuracy))\n}\n\n\nclass Metrics(labelsAndPreds: RDD[(Double, Double)]) extends java.io.Serializable {\n\n    private def filterCount(lftBnd:Int,rtBnd:Int):Double = labelsAndPreds\n                                                           .map(x => (x._1.toInt, x._2.toInt))\n                                                           .filter(_ == (lftBnd,rtBnd)).count()\n\n    lazy val tp = filterCount(1,1)  // true positives\n    lazy val tn = filterCount(0,0)  // true negatives\n    lazy val fp = filterCount(0,1)  // false positives\n    lazy val fn = filterCount(1,0)  // false negatives\n\n    lazy val precision = tp / (tp+fp)\n    lazy val recall = tp / (tp+fn)\n    lazy val F1 = 2*precision*recall / (precision+recall)\n    lazy val accuracy = (tp+tn) / (tp+tn+fp+fn)\n}","user":"anonymous","dateUpdated":"2019-09-08T03:31:34-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd._\nimport org.apache.spark.rdd.RDD\neval_metrics: (labelsAndPreds: org.apache.spark.rdd.RDD[(Double, Double)])(Array[Double], Array[Double])\ndefined class Metrics\n"}]},"apps":[],"jobName":"paragraph_1566723077220_-600109699","id":"20190825-015117_1946128941","dateCreated":"2019-08-25T01:51:17-0700","dateStarted":"2019-09-08T03:31:34-0700","dateFinished":"2019-09-08T03:31:35-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31994"},{"title":"Evaluate model on test data","text":"%spark\nprintln(validationData)\nval predictionsResultsComparedToActual = validationData.map { point =>\n    val prediction = predictFlightDelaysRFModel.predict(point.features)\n    (point.label, prediction)\n}\nval modelMetrics = new Metrics(predictionsResultsComparedToActual)\nprintln(\"accuracy = %.2f\"\n        .format(modelMetrics.accuracy))\n","user":"anonymous","dateUpdated":"2019-09-08T03:32:16-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"MapPartitionsRDD[96] at map at <console>:114\naccuracy = 0.79\npredictionsResultsComparedToActual: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[145] at map at <console>:125\nmodelMetrics: Metrics = Metrics@7066f3fd\n"}]},"apps":[],"jobName":"paragraph_1566718259390_491149597","id":"20190825-003059_736568661","dateCreated":"2019-08-25T00:30:59-0700","dateStarted":"2019-09-08T03:32:16-0700","dateFinished":"2019-09-08T03:32:23-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31995"},{"text":"%md\n\n\nPU with Spark streaming large time window and try to add pridicat pushdown for maximizing pref\n\nIntro per paragraph\n\n*Predicat push down \n\n*Change routing to tail_number\n* agrregation over tail_number\n\n* Use the model\n\n* Same zookeeper?\n* Feature vectore decision tree analisys\n\n*\n","user":"anonymous","dateUpdated":"2019-09-05T06:52:51-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:1: error: ';' expected but 'with' found.\nPU with Spark streaming large time window and try to add pridicat pushdown for maximizing pref\n   ^\n"}]},"apps":[],"jobName":"paragraph_1566736901034_1612159138","id":"20190825-054141_2133619741","dateCreated":"2019-08-25T05:41:41-0700","dateStarted":"2019-09-05T06:51:12-0700","dateFinished":"2019-09-05T06:51:12-0700","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:31996"},{"user":"anonymous","dateUpdated":"2019-08-25T04:26:24-0700","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1566373322196_-17263559","id":"20190821-004202_1739500621","dateCreated":"2019-08-21T00:42:02-0700","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:31997"}],"name":"Getting Started/FlightDelays","id":"GETTING-STARTED","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"insightedge_jdbc:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}
